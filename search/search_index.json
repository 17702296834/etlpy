{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"etlpy: A streaming DSL in Python Intro etlpy is a function library written in Python, you can write code in even one line to do complicated web crawler, file processing and data filtering, which can be integred with Pandas, requests. etlpy\u662f\u7eafPython\u5f00\u53d1\u7684\u51fd\u6570\u5e93\uff0c\u5b9e\u73b0\u6d41\u5f0fDSL(\u9886\u57df\u7279\u5b9a\u8bed\u8a00)\uff0c\u80fd\u4e00\u884c\u5185\u5b8c\u6210\u722c\u866b\uff0c\u6587\u4ef6\u5904\u7406\u548c\u6570\u636e\u6e05\u6d17\u7b49\u3002\u80fd\u548cpandas\u7b49\u7c7b\u5e93\u5145\u5206\u96c6\u6210\u3002\u7eaf\u94fe\u5f0f\u64cd\u4f5c\uff0c\u4ee3\u7801\u6781\u7b80\u3002 The design philosophy comes from: - bash pipeline in linux - Linq in C# - filter system in jinja2(a template engine) - flink and blink - Hawk by same author. \u5b83\u548clinux\u7684bash pipeline,C#\u7684Linq, jinja2\u7684\u8fc7\u6ee4\u5668(filter)\u4ee5\u53ca\u4f5c\u8005\u672c\u4eba\u5f00\u53d1\u7684Hawk\u6709\u9ad8\u5ea6\u7684\u76f8\u4f3c\u6027\u3002 the following code can get html from homepage to page 10 in website cnblogs: \u4e0b\u9762\u4e00\u884c\u4ee3\u7801\u5b9e\u73b0\u4e86\u83b7\u53d6\u535a\u5ba2\u56ed\u7b2c1\u523010\u9875\u7684\u6240\u6709html: from etlpy import * t= task().p.create(range(1,10)).cp('p:html').format('http://www.cnblogs.com/p{}').get() for data in t: print data It means generate num from 1 to 10 in column p, merge column p to column html, then format string as url like below, send web requests to the certain url and get the html. Finally, you can get all data from t using iterator. \u610f\u601d\u662f\u6307\uff1a\u5728p\u5217\u751f\u6210\u4ece1\u523010\u7684\u6570\uff0c\u62f7\u8d1dp\u5217\u5230html\u5217\uff0c\u5c06html\u5217\u5408\u5e76\u4e3aurl,\u5e76\u53d1\u9001web\u8bf7\u6c42\uff0c\u6700\u540e\u7684html\u6b63\u6587\u4fdd\u5b58\u5728html\u5217 etlpy supports: - Python2 3 - http proxies, get/posts, really same as famous Python requests library - regex, filter, html format and clean - running code in parallel mode without modifying code. etlpy\u7684\u7279\u6027\u6709\uff1a \u540c\u65f6\u652f\u6301python2\u548cpython3 \u5185\u7f6e\u65b9\u4fbf\u7684\u4ee3\u7406\uff0chttp get/post\u8bf7\u6c42\uff0c\u5199\u6cd5\u4e0erequests\u5e93\u975e\u5e38\u76f8\u4f3c \u5185\u7f6e\u6b63\u5219\u89e3\u6790\uff0chtml\u8f6c\u4e49\uff0cjson\u8f6c\u6362\u7b49\u6570\u636e\u6e05\u6d17\u529f\u80fd\uff0c\u76f4\u63a5\u8f93\u51fa \u80fd\u65b9\u4fbf\u5730\u5c06\u4efb\u52a1\u6309\u7167\u534f\u7a0b\uff0c\u7ebf\u7a0b\uff0c\u8fdb\u7a0b\uff0c\u548c\u591a\u673a\u5206\u5e03\u5f0f\u7684\u65b9\u5f0f\u8fdb\u884c\u4efb\u52a1\u5e76\u884c","title":"1.\u7efc\u8ff0"},{"location":"#etlpy-a-streaming-dsl-in-python","text":"","title":"etlpy: A streaming DSL in Python"},{"location":"#intro","text":"etlpy is a function library written in Python, you can write code in even one line to do complicated web crawler, file processing and data filtering, which can be integred with Pandas, requests. etlpy\u662f\u7eafPython\u5f00\u53d1\u7684\u51fd\u6570\u5e93\uff0c\u5b9e\u73b0\u6d41\u5f0fDSL(\u9886\u57df\u7279\u5b9a\u8bed\u8a00)\uff0c\u80fd\u4e00\u884c\u5185\u5b8c\u6210\u722c\u866b\uff0c\u6587\u4ef6\u5904\u7406\u548c\u6570\u636e\u6e05\u6d17\u7b49\u3002\u80fd\u548cpandas\u7b49\u7c7b\u5e93\u5145\u5206\u96c6\u6210\u3002\u7eaf\u94fe\u5f0f\u64cd\u4f5c\uff0c\u4ee3\u7801\u6781\u7b80\u3002 The design philosophy comes from: - bash pipeline in linux - Linq in C# - filter system in jinja2(a template engine) - flink and blink - Hawk by same author. \u5b83\u548clinux\u7684bash pipeline,C#\u7684Linq, jinja2\u7684\u8fc7\u6ee4\u5668(filter)\u4ee5\u53ca\u4f5c\u8005\u672c\u4eba\u5f00\u53d1\u7684Hawk\u6709\u9ad8\u5ea6\u7684\u76f8\u4f3c\u6027\u3002 the following code can get html from homepage to page 10 in website cnblogs: \u4e0b\u9762\u4e00\u884c\u4ee3\u7801\u5b9e\u73b0\u4e86\u83b7\u53d6\u535a\u5ba2\u56ed\u7b2c1\u523010\u9875\u7684\u6240\u6709html: from etlpy import * t= task().p.create(range(1,10)).cp('p:html').format('http://www.cnblogs.com/p{}').get() for data in t: print data It means generate num from 1 to 10 in column p, merge column p to column html, then format string as url like below, send web requests to the certain url and get the html. Finally, you can get all data from t using iterator. \u610f\u601d\u662f\u6307\uff1a\u5728p\u5217\u751f\u6210\u4ece1\u523010\u7684\u6570\uff0c\u62f7\u8d1dp\u5217\u5230html\u5217\uff0c\u5c06html\u5217\u5408\u5e76\u4e3aurl,\u5e76\u53d1\u9001web\u8bf7\u6c42\uff0c\u6700\u540e\u7684html\u6b63\u6587\u4fdd\u5b58\u5728html\u5217 etlpy supports: - Python2 3 - http proxies, get/posts, really same as famous Python requests library - regex, filter, html format and clean - running code in parallel mode without modifying code. etlpy\u7684\u7279\u6027\u6709\uff1a \u540c\u65f6\u652f\u6301python2\u548cpython3 \u5185\u7f6e\u65b9\u4fbf\u7684\u4ee3\u7406\uff0chttp get/post\u8bf7\u6c42\uff0c\u5199\u6cd5\u4e0erequests\u5e93\u975e\u5e38\u76f8\u4f3c \u5185\u7f6e\u6b63\u5219\u89e3\u6790\uff0chtml\u8f6c\u4e49\uff0cjson\u8f6c\u6362\u7b49\u6570\u636e\u6e05\u6d17\u529f\u80fd\uff0c\u76f4\u63a5\u8f93\u51fa \u80fd\u65b9\u4fbf\u5730\u5c06\u4efb\u52a1\u6309\u7167\u534f\u7a0b\uff0c\u7ebf\u7a0b\uff0c\u8fdb\u7a0b\uff0c\u548c\u591a\u673a\u5206\u5e03\u5f0f\u7684\u65b9\u5f0f\u8fdb\u884c\u4efb\u52a1\u5e76\u884c","title":"Intro"}]}